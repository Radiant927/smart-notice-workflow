# 设计报告

## 项目概述

本项目旨在开发一个基于自然语言处理的智能班会通知分组推送系统。系统通过利用 **ChatGLM3-6B** 模型生成班会通知，并通过 **LangChain** 和 **Coze** 实现自动化工作流。系统的目标是提升班会通知的生成与分发效率，并实现通知的自动化处理与推送。

## 技术栈

- **ChatGLM3-6B**：用于生成班会通知的语言模型。
- **LangChain**：用于构建工作流并将模型与其他组件整合。
- **Coze**：用于处理通知的分发与推送。
- **FastAPI**：作为后端 API 服务框架，提供高效的 Web 服务接口供 LangChain 和 Coze 调用。

## 项目架构

### 1. API 层

使用 **FastAPI** 构建 RESTful API 服务，该服务负责接收外部请求并返回班会通知生成的结果。核心的 API 包括：

- **POST /chat**：接受聊天信息并通过 ChatGLM3-6B 模型生成班会通知。
- **POST /generate_notice**：生成符合条件的班会通知并返回。

### 2. 模型层

- **ChatGLM3-6B 模型**：该模型是一个强大的中文生成模型，用于处理生成班会通知的任务。
- **模型加载与推理**：通过 `deploy_chatglm.py` 脚本加载并运行模型进行推理。模型的配置文件 `chatglm_config.json` 用于指定模型路径及其他参数。

### 3. 工作流层

- **LangChain**：用于组织工作流，包括提取输入数据、调用生成模型、执行后续处理等。
- **Coze**：用于将生成的班会通知推送给指定的班级群体，支持高效的通知推送。

## 关键设计决策

### 1. 选择 ChatGLM3-6B 模型

该模型在中文文本生成上表现优秀，能够准确生成符合中文语言习惯的班会通知。由于项目主要面向中文用户群体，使用 ChatGLM3-6B 能够确保生成的通知内容符合需求。

### 2. 使用 FastAPI 构建 API 服务

**FastAPI** 提供了异步支持和高并发能力，能够有效处理大量并发请求，适合高效服务需求。在这项目中，我们使用 FastAPI 来封装所有的接口服务，并且能轻松集成其他框架（如 LangChain 和 Coze）。

### 3. 工作流自动化

为了提高系统的自动化程度，我们使用 **LangChain** 作为工作流构建框架，将数据提取、通知生成、通知推送等任务串联起来，确保整个流程的高效执行。而 **Coze** 则承担了推送通知的任务，能够快速将生成的通知分发给指定的用户群体。

### 4. 模型推理的性能优化

通过将模型加载和推理部分独立成模块，我们确保了推理性能的可扩展性。此外，使用 **GPU 加速**（如果可能）能够进一步提升模型推理速度，尤其是在大规模数据的处理上。

## 项目实现

### 1. API 服务

`api_server.py` 实现了 FastAPI 服务，提供了如下接口：

- `/chat`：接收请求并调用 ChatGLM3-6B 模型生成通知。
- `/generate_notice`：生成班会通知并返回推送的通知内容。

### 2. 模型加载与推理

`deploy_chatglm.py` 用于加载和执行 ChatGLM3-6B 模型，并通过 `chatglm_config.json` 文件配置模型路径。输入数据将通过该脚本传递给模型进行推理。

### 3. 工作流集成

使用 **LangChain** 构建的工作流将整个流程分成多个步骤：

1. 数据提取：从数据库或文件中提取通知数据。
2. 通知生成：通过模型生成通知内容。
3. 通知推送：通过 **Coze** 将通知推送给目标用户。

### 4. 通知推送

**Coze** 服务用于将生成的班会通知推送到目标群体，确保通知能及时送达。

## 总结

本项目通过整合先进的自然语言生成技术和高效的工作流管理框架，能够自动化生成并推送班会通知。系统的自动化程度高、响应速度快，能够有效提高班会通知的分发效率，并为用户提供便捷的通知服务。
